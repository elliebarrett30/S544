# -*- coding: utf-8 -*-
"""Activity 6.1: Polynomial Regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QdYAJNJ9N94JhqpCiGQJUaJCZKw30XiP

# Palmer Penguins Modeling

Import the Palmer Penguins dataset and print out the first few rows.

Suppose we want to predict `bill_depth_mm` using the other variables in the dataset.

Which variables would we need to **dummify**?
"""

!pip install palmerpenguins

# Code Here
import pandas as pd
from palmerpenguins import load_penguins

penguins = load_penguins()
penguins.head()

# We will need to dummify species, island, and sex

"""Let's use `bill_length_mm` to predict `bill_depth_mm`. Prepare your data and fit the following models on the entire dataset:

* Simple linear regression (e.g. straight-line) model
* Quadratic (degree 2 polynomial) model
* Cubic (degree 3 polynomial) model
* Degree 10 polynomial model

Make predictions for each model and plot your fitted models on the scatterplot.
"""

# Your code here

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from palmerpenguins import load_penguins
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

penguins = load_penguins()

penguins = penguins.dropna(subset=['bill_length_mm', 'bill_depth_mm'])

X = penguins['bill_length_mm'].values.reshape(-1, 1)
y = penguins['bill_depth_mm']

x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)

# 1. Simple Linear Regression
linear_model = LinearRegression()
linear_model.fit(X, y)

# 2. Quadratic Model (degree = 2)
quadratic = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
quadratic.fit(X, y)

# 3. Cubic Model (degree = 3)
cubic = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())
cubic.fit(X, y)

# 4. Degree 10 Polynomial Model
degree_ten = make_pipeline(PolynomialFeatures(degree=10), LinearRegression())
degree_ten.fit(X, y)

plt.figure(figsize=(10, 6))
plt.scatter(X, y, label='Data', alpha=0.5)
plt.plot(x_range, linear_model.predict(x_range), label='Linear', color='red')
plt.plot(x_range, quadratic.predict(x_range), label='Quadratic', color='green')
plt.plot(x_range, cubic.predict(x_range), label='Cubic', color='purple')
plt.plot(x_range, degree_ten.predict(x_range), label='Degree 10', color='orange')

plt.xlabel('Bill Length (mm)')
plt.ylabel('Bill Depth (mm)')
plt.title('Polynomial Regression Models for Bill Depth vs. Bill Length')
plt.legend()
plt.grid(True)
plt.show()

"""* Are any of the models above underfitting the data? If so, which ones and how can you tell?
* Are any of thhe models above overfitting the data? If so, which ones and how can you tell?
* Which of the above models do you think fits the data best and why?

Model 1 is underfitting because itâ€™s too simple, showing high training and test errors. Model 4 is overfitting because it fits the training data very well but performs worse on the test set. Model 2 or 3 fit best because they balance bias and variance, achieving the lowest test error.
"""